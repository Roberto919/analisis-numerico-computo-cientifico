

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>3.1 Definición de problemas de optimización, conjuntos y funciones convexas</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="3.2 Algoritmos de descenso y búsqueda de línea para funciones convexas" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_funciones_convexas.html" />
    <link rel="prev" title="2.4 Valores, vectores singulares y algoritmos para calcular la SVD" href="../../II.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   Optimización
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  I. Cómputo científico
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.1/Analisis_numerico_y_computo_cientifico.html">
   1.1 Análisis numérico y cómputo científico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.2/Sistema_de_punto_flotante.html">
   1.2 Sistema de punto flotante
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.3/Normas_vectoriales_y_matriciales.html">
   1.3 Normas vectoriales y matriciales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.4/Condicion_de_un_problema_y_estabilidad_de_un_algoritmo.html">
   1.4 Condición de un problema y estabilidad de un algoritmo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.5/Definicion_de_funcion_continuidad_derivada.html">
   1.5 Definición de función, continuidad y derivada
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.6/Polinomios_de_Taylor_y_diferenciacion_numerica.html">
   1.6 Polinomios de Taylor y diferenciación numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../I.computo_cientifico/1.7/Integracion_numerica.html">
   1.7 Integración Numérica
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  II. Cómputo matricial
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.1/Operaciones_y_transformaciones_basicas_del_Algebra_Lineal_Numerica.html">
   2.1 Operaciones y transformaciones básicas del Álgebra Lineal Numérica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.2/Eigenvalores_y_eigenvectores.html">
   2.2 Eigenvalores y eigenvectores
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.3/Algoritmos_y_aplicaciones_de_eigenvalores_eigenvectores_de_una_matriz.html">
   2.3 Algoritmos y aplicaciones de eigenvalores y eigenvectores de una matriz
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../II.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html">
   2.4 Valores, vectores singulares y algoritmos para calcular la SVD
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  III. Optimización convexa
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3.1 Definición de problemas de optimización, conjuntos y funciones convexas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_funciones_convexas.html">
   3.2 Algoritmos de descenso y búsqueda de línea para funciones convexas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3.3/Ecuaciones_no_lineales.html">
   3.3 Ecuaciones no lineales
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/III.optimizacion_convexa/3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/palmoreck/dockerfiles-for-binder/jupyterlab_optimizacion?urlpath=lab/tree/analisis-numerico-computo-cientifico/libro_optimizacion/temas/III.optimizacion_convexa/3.1/Definicion_de_problema_optimizacion_conjuntos_y_funciones_convexas.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> On this page
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problemas-de-optimizacion-numerica">
   ¿Problemas de optimización numérica?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ejemplo">
     Ejemplo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Ejemplo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizacion-numerica-en-ciencia-de-datos">
   Optimización numérica en ciencia de datos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimizacion-numerica-y-machine-learning">
     Optimización numérica y
     <em>
      machine learning
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#del-small-scale-al-large-scale-machine-learning">
     Del
     <em>
      small scale
     </em>
     al
     <em>
      large scale machine learning
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizacion-numerica-convexa">
   ¿Optimización numérica convexa?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problema-estandar-de-optimizacion">
   Problema estándar de optimización
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dominio-del-problema-de-optimizacion-y-puntos-factibles">
   Dominio del problema de optimización y puntos factibles
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#valor-optimo-del-problema-de-optimizacion">
   Valor óptimo del problema de optimización
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#punto-optimo-del-problema-de-optimizacion">
   Punto óptimo del problema de optimización
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimo-local">
   Óptimo local
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#restricciones-activas-no-activas-y-redundantes">
   Restricciones activas, no activas y redundantes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problemas-de-optimizacion-convexa-en-su-forma-estandar-o-canonica">
   Problemas de optimización convexa en su forma estándar o canónica
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#funcion-convexa">
   Función convexa
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#propiedades">
     Propiedades
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conjuntos-convexos">
   Conjuntos convexos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linea-y-segmentos-de-linea">
     Línea y segmentos de línea
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conjunto-convexo">
     Conjunto convexo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejemplos-de-funciones-convexas-y-concavas">
   Ejemplos de funciones convexas y cóncavas
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resultados-utiles-de-teoria-de-convexidad">
   Resultados útiles de teoría de convexidad
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-funciones-convexas-concavas">
     Sobre funciones convexas/cóncavas
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-problemas-de-optimizacion">
     Sobre problemas de optimización
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-puntos-criticos">
     Sobre puntos críticos
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#funcion-fuertemente-convexa">
   Función fuertemente convexa
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="definicion-de-problemas-de-optimizacion-conjuntos-y-funciones-convexas">
<span id="dpocfc"></span><h1>3.1 Definición de problemas de optimización, conjuntos y funciones convexas<a class="headerlink" href="#definicion-de-problemas-de-optimizacion-conjuntos-y-funciones-convexas" title="Permalink to this headline">¶</a></h1>
<div class="admonition-notas-para-contenedor-de-docker admonition">
<p class="admonition-title">Notas para contenedor de docker:</p>
<p>Comando de docker para ejecución de la nota de forma local:</p>
<p>nota: cambiar <code class="docutils literal notranslate"><span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;</span></code> por la ruta de directorio que se desea mapear a <code class="docutils literal notranslate"><span class="pre">/datos</span></code> dentro del contenedor de docker.</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">--rm</span> <span class="pre">-v</span> <span class="pre">&lt;ruta</span> <span class="pre">a</span> <span class="pre">mi</span> <span class="pre">directorio&gt;:/datos</span> <span class="pre">--name</span> <span class="pre">jupyterlab_optimizacion</span> <span class="pre">-p</span> <span class="pre">8888:8888</span> <span class="pre">-d</span> <span class="pre">palmoreck/jupyterlab_optimizacion:2.1.4</span></code></p>
<p>password para jupyterlab: <code class="docutils literal notranslate"><span class="pre">qwerty</span></code></p>
<p>Detener el contenedor de docker:</p>
<p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">stop</span> <span class="pre">jupyterlab_optimizacion</span></code></p>
<p>Documentación de la imagen de docker <code class="docutils literal notranslate"><span class="pre">palmoreck/jupyterlab_optimizacion:2.1.4</span></code> en <a class="reference external" href="https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion">liga</a>.</p>
</div>
<hr class="docutils" />
<p>Nota generada a partir de <a class="reference external" href="https://www.dropbox.com/s/qb3swgkpaps7yba/4.1.Introduccion_optimizacion_convexa.pdf?dl=0">liga1</a>, <a class="reference external" href="https://www.dropbox.com/s/6isby5h1e5f2yzs/4.2.Problemas_de_optimizacion_convexa.pdf?dl=0">liga2</a>, <a class="reference external" href="https://www.dropbox.com/s/ko86cce1olbtsbk/4.3.1.Teoria_de_convexidad_Conjuntos_convexos.pdf?dl=0">liga3</a>, <a class="reference external" href="https://www.dropbox.com/s/mmd1uzvwhdwsyiu/4.3.2.Teoria_de_convexidad_Funciones_convexas.pdf?dl=0">liga4</a>, <a class="reference external" href="https://drive.google.com/file/d/1xtkxPCx05Xg4Dj7JZoQ-LusBDrtYUqOF/view">liga5</a>, <a class="reference external" href="https://drive.google.com/file/d/16-_PvWNaO0Zc9x04-SRsxCRdn5fxebf2/view">liga6</a>.</p>
<div class="tip admonition">
<p class="admonition-title">Al final de esta nota el y la lectora:</p>
<ul class="simple">
<li><p>Conocerá la definición de un problema de optimización, algunos ejemplos, definiciones y resultados que serán utilizados en los métodos para resolver problemas de optimización con énfasis en funciones convexas.</p></li>
<li><p>Tendrá una lista ejemplo de funciones convexas utilizadas en aplicaciones.</p></li>
</ul>
</div>
<div class="section" id="problemas-de-optimizacion-numerica">
<h2>¿Problemas de optimización numérica?<a class="headerlink" href="#problemas-de-optimizacion-numerica" title="Permalink to this headline">¶</a></h2>
<p>Una gran cantidad de aplicaciones plantean problemas de optimización. Tenemos problemas básicos que se presentan en cursos iniciales de cálculo:</p>
<p><em>Una caja con base y tapa cuadradas debe tener un volumen de <span class="math notranslate nohighlight">\(100 cm^3\)</span>. Encuentre las dimensiones de la caja que minimicen la cantidad de material.</em></p>
<p>Y tenemos más especializados que encontramos en áreas como estadística, ingeniería, finanzas o aprendizaje de máquina, <em>aka machine learning</em>:</p>
<ul class="simple">
<li><p>Ajustar un modelo de regresión lineal a un conjunto de datos.</p></li>
<li><p>Buscar la mejor forma de invertir un capital en un conjunto de activos.</p></li>
<li><p>Elección del ancho y largo de un dispositivo en un circuito electrónico.</p></li>
<li><p>Ajustar un modelo que clasifique un conjunto de datos.</p></li>
</ul>
<p>En general un problema de optimización matemática o numérica tiene la forma:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min f_o(x)\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:} f_i(x) \leq b_i, i=1,\dots, m\]</div>
<p>donde: <span class="math notranslate nohighlight">\(x=(x_1,x_2,\dots, x_n)^T\)</span> es la <strong>variable de optimización del problema</strong>, la función <span class="math notranslate nohighlight">\(f_o: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span> es la <strong>función objetivo</strong>, las funciones <span class="math notranslate nohighlight">\(f_i: \mathbb{R}^n \rightarrow \mathbb{R}, i=1,\dots,m\)</span> son las <strong>funciones de restricción</strong> (aquí se colocan únicamente desigualdades pero pueden ser sólo igualdades o bien una combinación de ellas) y las constantes <span class="math notranslate nohighlight">\(b_1,b_2,\dots, b_m\)</span> son los <strong>límites o cotas de las restricciones</strong>.</p>
<p>Un vector <span class="math notranslate nohighlight">\(x^* \in \mathbb{R}^n\)</span> es nombrado <strong>óptimo</strong> o solución del problema anterior si tiene el valor más pequeño de entre todos los vectores <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> que satisfacen las restricciones. Por ejemplo, si <span class="math notranslate nohighlight">\(z \in \mathbb{R}^n\)</span> satisface <span class="math notranslate nohighlight">\(f_1(z) \leq b_1, f_2(z) \leq b_2, \dots, f_m(z) \leq b_m\)</span> y <span class="math notranslate nohighlight">\(x^*\)</span> es óptimo entonces <span class="math notranslate nohighlight">\(f_o(z) \geq f_o(x^*)\)</span>.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>A grandes rasgos dos problemas de optimización son equivalentes si con la solución de uno de ellos se obtiene la solución del otro y viceversa.</p>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Se consideran funciones objetivo <span class="math notranslate nohighlight">\(f_o: \mathbb{R}^n \rightarrow \mathbb{R}\)</span>, sin embargo, hay formulaciones que utilizan <span class="math notranslate nohighlight">\(f_o: \mathbb{R}^n \rightarrow \mathbb{R}^q\)</span>. Tales formulaciones pueden hallarlas en la optimización multicriterio, multiobjetivo, vectorial o también nombrada Pareto, ver <a class="reference external" href="https://en.wikipedia.org/wiki/Multi-objective_optimization">Multi objective optimization</a>.</p></li>
<li><p>El problema de optimización definido utiliza una forma de minimización y no de maximización. Típicamente en la literatura por convención se consideran problemas de este tipo. Además minimizar <span class="math notranslate nohighlight">\(f_o\)</span> y maximizar <span class="math notranslate nohighlight">\(-f_o\)</span> son <strong>problemas de optimización equivalentes</strong>.</p></li>
</ul>
</div>
<div class="section" id="ejemplo">
<h3>Ejemplo<a class="headerlink" href="#ejemplo" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{x \in \mathbb{R}^n} ||x||_2\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:} Ax \leq b\]</div>
<p>con <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}, b \in \mathbb{R}^m\)</span>. En este problema buscamos el vector <span class="math notranslate nohighlight">\(x\)</span> que es solución del problema <span class="math notranslate nohighlight">\(Ax \leq b\)</span> con <strong>mínima norma Euclidiana</strong>. La función objetivo es <span class="math notranslate nohighlight">\(f_o(x)=||x||_2\)</span>, las funciones de restricción son las desigualdades lineales <span class="math notranslate nohighlight">\(f_i(x) = a_i^Tx \leq b_i\)</span> con <span class="math notranslate nohighlight">\(a_i\)</span> <span class="math notranslate nohighlight">\(i\)</span>-ésimo renglón de <span class="math notranslate nohighlight">\(A\)</span> y <span class="math notranslate nohighlight">\(b_i\)</span> <span class="math notranslate nohighlight">\(i\)</span>-ésima componente de <span class="math notranslate nohighlight">\(b\)</span>, <span class="math notranslate nohighlight">\(\forall i=1,\dots,m\)</span>.</p>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Un problema similar (sólo modificando desigualdad por igualdad) lo encontramos al resolver un sistema de ecuaciones lineales <span class="math notranslate nohighlight">\(Ax=b\)</span> <em>underdetermined</em> en el que <span class="math notranslate nohighlight">\(m &lt; n\)</span> y se busca el vector <span class="math notranslate nohighlight">\(x\)</span> con mínima norma Euclidiana que satisfaga tal sistema. Este sistema puede tener infinitas soluciones o ninguna solución.</p>
</div>
</div>
<div class="section" id="id1">
<h3>Ejemplo<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Encuentra el punto en la gráfica de <span class="math notranslate nohighlight">\(y=x^2\)</span> que es más cercano al punto <span class="math notranslate nohighlight">\(P=(1,0)\)</span> bajo la norma Euclidiana.</p>
<p>Deseamos minimizar la cantidad <span class="math notranslate nohighlight">\(||(1,0)-(x,y)||_2\)</span>. Además <span class="math notranslate nohighlight">\(y = y(x)\)</span> por lo que definiendo la función objetivo <span class="math notranslate nohighlight">\(f_o(x) = ||(1,0)-(x,x^2)||_2=||(1-x,-x^2)||_2=\sqrt{(1-x)^2+x^4}\)</span>, el problema de optimización (sin restricciones) es:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min_{x \in \text{dom}f_o}\sqrt{(1-x)^2+x^4}\]</div>
</div>
</div>
<div class="section" id="optimizacion-numerica-en-ciencia-de-datos">
<h2>Optimización numérica en ciencia de datos<a class="headerlink" href="#optimizacion-numerica-en-ciencia-de-datos" title="Permalink to this headline">¶</a></h2>
<div class="sidebar">
<p class="sidebar-title">Optimización de código o software</p>
<p>La implementación de los métodos o algoritmos en el contexto de grandes cantidades de datos o big data es crítica al ir a la práctica pues de esto depende que nuestra(s) máquina(s) tarde meses, semanas, días u horas para resolver problemas que se presentan en este contexto. En este contexto la <a class="reference external" href="https://en.wikipedia.org/wiki/Program_optimization">optimización de código o de software</a> nos ayuda a la eficiencia.</p>
</div>
<p>La ciencia de datos apunta al desarrollo de técnicas y se apoya de aplicaciones de <em>machine learning</em> para la extracción de conocimiento útil tomando como fuente de información las grandes cantidades de datos. Algunas de las aplicaciones son:</p>
<ul class="simple">
<li><p>Clasificación de documentos o textos: detección de <em>spam</em>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Natural_language_processing">Procesamiento de lenguaje natural</a>:  <a class="reference external" href="https://en.wikipedia.org/wiki/Named-entity_recognition">named-entity recognition</a>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Speech_recognition">Reconocimiento de voz</a>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Computer_vision">Visión por computadora</a>: reconocimiento de rostros o imágenes.</p></li>
<li><p>Detección de fraude.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Pattern_recognition">Reconocimiento de patrones</a>.</p></li>
<li><p>Diagnóstico médico.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Recommender_system">Sistemas de recomendación</a>.</p></li>
</ul>
<p>Las aplicaciones anteriores involucran problemas como son:</p>
<ul class="simple">
<li><p>Clasificación.</p></li>
<li><p>Regresión.</p></li>
<li><p><em>Ranking</em>.</p></li>
<li><p><em>Clustering</em>.</p></li>
<li><p>Reducción de la dimensionalidad.</p></li>
</ul>
<div class="section" id="optimizacion-numerica-y-machine-learning">
<h3>Optimización numérica y <em>machine learning</em><a class="headerlink" href="#optimizacion-numerica-y-machine-learning" title="Permalink to this headline">¶</a></h3>
<p>En cada una de las aplicaciones o problemas anteriores se utilizan <strong>funciones de pérdida</strong> que guían el proceso de aprendizaje. Tal proceso involucra <strong>optimización parámetros</strong> de la función de pérdida. Por ejemplo, si la función de pérdida en un problema de regresión es una pérdida cuadrática <span class="math notranslate nohighlight">\(\mathcal{L}(y,\hat{y}) = (\hat{y}-y)^2\)</span> con <span class="math notranslate nohighlight">\(\hat{y} = \hat{\beta}_0 + \hat{\beta_1}x\)</span>, entonces el vector de parámetros a optimizar (aprender) es <span class="math notranslate nohighlight">\(\beta= \left[ \begin{array}{c} \beta_0\\ \beta_1 \end{array} \right]\)</span>.</p>
<div class="sidebar">
<p class="sidebar-title">Un poco de historia…</p>
<p>La IA o Inteligencia Artificial es una rama de la Ciencia de la Computación que atrajo un gran interés en 1950.</p>
<p>Colloquially, the term artificial intelligence is often used to describe machines (or computers) that mimic “cognitive” functions that humans associate with the human mind, such as learning and problem solving (<a class="reference external" href="https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach">S. J. Russel, P. Norvig, 1995</a>)</p>
</div>
<p><em>Machine learning</em> no sólo se apoya de la optimización pues es un área de Inteligencia Artificial que utiliza técnicas estadísticas para el diseño de sistemas capaces de aplicaciones como las escritas anteriormente, de modo que hoy en día tenemos <em>statistical machine learning</em>. No obstante, uno de los <strong>pilares</strong> de <em>machine learning</em> o <em>statistical machine learning</em> es la optimización.</p>
<p><em>Machine learning</em> o <em>statistical machine learning</em> se apoya de las formulaciones y algoritmos en optimización. Sin embargo, también ha contribuido a ésta área desarrollando nuevos enfoques en los métodos o algoritmos para el tratamiento de grandes cantidades de datos o <em>big data</em> y estableciendo retos significativos no presentes en problemas clásicos de optimización. De hecho, al revisar literatura que intersecta estas dos disciplinas encontramos comunidades científicas que desarrollan o utilizan métodos o algoritmos exactos (ver <a class="reference external" href="https://en.wikipedia.org/wiki/Exact_algorithm">Exact algorithm</a>) y otras que utilizan métodos de optimización estocástica (ver <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_optimization">Stochastic optimization</a> y <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_approximation">Stochastic approximation</a>) basados en métodos o algoritmos aproximados (ver <a class="reference external" href="https://en.wikipedia.org/wiki/Approximation_algorithm">Approximation algorithm</a>). Hoy en día es común encontrar estudios que hacen referencia a <strong>modelos o métodos de aprendizaje</strong>.</p>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Como ejemplo de lo anterior considérese la técnica de <a class="reference external" href="https://en.wikipedia.org/wiki/Regularization_(mathematics)"><strong>regularización</strong></a> que en <em>machine learning</em> se utiliza para encontrar soluciones que generalicen y provean una explicación no compleja del fenómeno en estudio.</p>
<p>La regularización sigue el principio de la navaja de Occam, ver <a class="reference external" href="https://en.wikipedia.org/wiki/Occam%27s_razor">Occam’s razor</a>: para cualquier conjunto de observaciones en general se prefieren explicaciones simples a explicaciones más complicadas. Aunque la técnica de regularización es conocida en optimización, han sido varias las aplicaciones de <em>machine learning</em> las que la han posicionado como clave.</p>
</div>
</div>
<div class="section" id="del-small-scale-al-large-scale-machine-learning">
<h3>Del <em>small scale</em> al <em>large scale machine learning</em><a class="headerlink" href="#del-small-scale-al-large-scale-machine-learning" title="Permalink to this headline">¶</a></h3>
<div class="sidebar">
<p class="sidebar-title">Un poco de historia…</p>
<p>Un ejemplo de esto se observa en métodos de optimización desarrollados en la década de los <span class="math notranslate nohighlight">\(50\)</span>’s. Mientras que métodos tradicionales en optimización basados en el cálculo del gradiente y la Hessiana de una función son efectivos para problemas de aprendizaje <em>small-scale</em> (en los que  utilizamos un enfoque en <em><strong>batch</strong></em> o por lote), en el contexto del aprendizaje <em>large-scale</em>, el <strong>método de gradiente estocástico</strong> se posicionó en el centro de discusiones a inicios del siglo XXI.</p>
<p>El método de gradiente estocástico fue propuesto por Robbins y Monro en 1951, es un <strong>algoritmo estocástico</strong>. Ver <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent</a>.</p>
</div>
<p>El inicio del siglo XXI estuvo marcado, entre otros temas, por un incremento significativo en la generación de información. Esto puede contrastarse con el desarrollo de los procesadores de las máquinas, el cual tuvo un menor <em>performance</em> al del siglo XX. Asimismo, las mejoras en dispositivos de almacenamiento o <em>storage</em> y sistemas de <em>networking</em> abarató costos de almacenamiento y permitió tal incremento de información.  En este contexto, los modelos y métodos de <em>statistical machine learning</em> se vieron limitados por el tiempo de cómputo y no por el tamaño de muestra. La conclusión de esto fue una inclinación en la comunidad científica por el diseño o uso de métodos o modelos para procesar grandes cantidades de datos usando recursos computacionales comparativamente menores.</p>
</div>
</div>
<div class="section" id="optimizacion-numerica-convexa">
<h2>¿Optimización numérica convexa?<a class="headerlink" href="#optimizacion-numerica-convexa" title="Permalink to this headline">¶</a></h2>
<p>Aplicaciones de <em>machine learning</em> conducen al planteamiento de problemas de optimización convexa y no convexa. Por ejemplo en la aplicación de clasificación de textos, en donde se desea asignar un texto a clases definidas de acuerdo a su contenido (determinar si un documento de texto es sobre un tema), puede formularse un problema convexo a partir de una <strong>función de pérdida convexa</strong>.</p>
<div class="sidebar">
<p class="sidebar-title">Un poco de historia…</p>
<p>Los tipos de redes neuronales profundas, <em>deep neural networks</em>, que han sido mayormente usadas a inicios del siglo XXI son las mismas que las que eran populares en los años <span class="math notranslate nohighlight">\(90\)</span>’s. El éxito de éstos tipos y su uso primordialmente se debe a la disponibilidad de <em>larger datasets</em> y mayores recursos computacionales.</p>
</div>
<p>Como ejemplos de aplicaciones en la <strong>optimización no convexa</strong> están el reconocimiento de voz y reconocimiento de imágenes. El uso de <a class="reference external" href="https://en.wikipedia.org/wiki/Artificial_neural_network">redes neuronales</a> <a class="reference external" href="https://en.wikipedia.org/wiki/Deep_learning">profundas</a> ha tenido muy buen desempeño en tales aplicaciones haciendo uso de cómputo en la GPU, ver <a class="reference external" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a>, <a class="reference external" href="https://medium.com/limitlessai/2012-a-breakthrough-year-for-deep-learning-2a31a6796e73">2012: A Breakthrough Year for Deep Learning</a>. En este caso se utilizan <strong>funciones objetivo no lineales y no convexas</strong>.</p>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Desde los <span class="math notranslate nohighlight">\(40\)</span>’s se han desarrollado algoritmos para resolver problemas de optimización, se han analizado sus propiedades y se han desarrollado buenas implementaciones de software.  Sin embargo, una clase de problemas de optimización en los que encontramos métodos <strong>efectivos</strong> son los convexos.</p></li>
<li><p>Métodos para optimización no convexa utilizan parte de la teoría de convexidad desarrollada en optimización convexa. Además, un buen número de problemas de aprendizaje utilizan funciones de pérdida convexas.</p></li>
</ul>
</div>
</div>
<div class="section" id="problema-estandar-de-optimizacion">
<span id="pestopt"></span><h2>Problema estándar de optimización<a class="headerlink" href="#problema-estandar-de-optimizacion" title="Permalink to this headline">¶</a></h2>
<p>En lo que continúa se considera <span class="math notranslate nohighlight">\(f_0 = f_o\)</span> (el subíndice “0” y el subíndice “o” son iguales)</p>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Un problema estándar de optimización es:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min f_o(x)\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[f_i(x) \leq 0, \quad \forall i=1,\dots,m\]</div>
<div class="math notranslate nohighlight">
\[h_i(x) = 0, \quad \forall i=1,\dots,p\]</div>
<p>con <span class="math notranslate nohighlight">\(f_i: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> <span class="math notranslate nohighlight">\(\forall i=0,\dots,m\)</span>, <span class="math notranslate nohighlight">\(h_i: \mathbb{R}^n \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(\forall i=1,\dots,p\)</span>. <span class="math notranslate nohighlight">\(f_i\)</span> son las <strong>restricciones de desigualdad</strong>, <span class="math notranslate nohighlight">\(h_i\)</span> son las <strong>restricciones de igualdad</strong>.</p>
</div>
</div>
<div class="section" id="dominio-del-problema-de-optimizacion-y-puntos-factibles">
<h2>Dominio del problema de optimización y puntos factibles<a class="headerlink" href="#dominio-del-problema-de-optimizacion-y-puntos-factibles" title="Permalink to this headline">¶</a></h2>
<div class="admonition-definiciones admonition">
<p class="admonition-title">Definiciones</p>
<ul class="simple">
<li><p>El conjunto de puntos para los que la función objetivo y las funciones de restricción <span class="math notranslate nohighlight">\(f_i, h_i\)</span> están definidas se nombra <strong>dominio del problema de optimización</strong>, esto es:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathcal{D} = \bigcap_{i=0}^m\text{dom}f_i \cap \bigcap_{i=1}^p\text{dom}h_i.\]</div>
<ul class="simple">
<li><p>Un punto <span class="math notranslate nohighlight">\(x \in \mathcal{D}\)</span> se nombra <strong>factible</strong> si satisface las restricciones de igualdad y desigualdad. El conjunto de puntos factibles se nombra <strong>conjunto de factibilidad</strong>.</p></li>
<li><p>El <a class="reference internal" href="#pestopt"><span class="std std-ref">problema estándar de optimización</span></a> se nombra <strong>problema de optimización factible</strong> si existe <strong>al menos un punto factible</strong>, si no entonces es infactible.</p></li>
</ul>
</div>
</div>
<div class="section" id="valor-optimo-del-problema-de-optimizacion">
<h2>Valor óptimo del problema de optimización<a class="headerlink" href="#valor-optimo-del-problema-de-optimizacion" title="Permalink to this headline">¶</a></h2>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se asumen todos los puntos en el dominio del problema de optimización <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</div>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>El valor óptimo del problema se denota como <span class="math notranslate nohighlight">\(p^*\)</span>. En notación matemática es:</p>
<div class="math notranslate nohighlight">
\[p^* = \inf\{f_o(x) | f_i(x) \leq 0, \forall i=1,\dots,m, h_i(x) = 0 \forall i=1,\dots,p\}\]</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Si el problema es <strong>infactible</strong> entonces <span class="math notranslate nohighlight">\(p^* = \infty\)</span>.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(\exists x_k\)</span> factible tal que <span class="math notranslate nohighlight">\(f_o(x_k) \rightarrow -\infty\)</span> para <span class="math notranslate nohighlight">\(k \rightarrow \infty\)</span> entonces <span class="math notranslate nohighlight">\(p^*=-\infty\)</span> y se nombra <strong>problema de optimización no acotado por debajo</strong>.</p></li>
</ul>
</div>
</div>
<div class="section" id="punto-optimo-del-problema-de-optimizacion">
<span id="poptprobopt"></span><h2>Punto óptimo del problema de optimización<a class="headerlink" href="#punto-optimo-del-problema-de-optimizacion" title="Permalink to this headline">¶</a></h2>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se asumen todos los puntos en el dominio del problema de optimización <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</div>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p><span class="math notranslate nohighlight">\(x^*\)</span> es <strong>punto óptimo</strong> si es factible y <span class="math notranslate nohighlight">\(f_o(x^*) = p^*\)</span>.</p>
<p>El conjunto de óptimos se nombra <strong>conjunto óptimo</strong> y se denota:</p>
<div class="math notranslate nohighlight">
\[X_{\text{opt}} = \{x | f_i(x) \leq 0 \forall i=1,\dots,m, h_i(x) =0 \forall i=1,\dots,p, f_o(x) = p^*\}\]</div>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>La propiedad de un punto óptimo <span class="math notranslate nohighlight">\(x^*\)</span> es que si <span class="math notranslate nohighlight">\(z\)</span> satisface las restricciones <span class="math notranslate nohighlight">\(f_i(z) \leq 0\)</span> <span class="math notranslate nohighlight">\(\forall i=1,...,m\)</span>, <span class="math notranslate nohighlight">\(h_i(z)=0\)</span> <span class="math notranslate nohighlight">\(\forall i=1,..,p\)</span> se tiene: <span class="math notranslate nohighlight">\(f(x^*) \leq f(z)\)</span>. Es <strong>óptimo estricto</strong> si <span class="math notranslate nohighlight">\(z\)</span> satisface las restricciones y <span class="math notranslate nohighlight">\(f_o(x^*) &lt; f_o(z)\)</span>.</p></li>
<li><p>Si existe un punto óptimo se dice que el <strong>valor óptimo se alcanza</strong> y por tanto el problema de optimización tiene solución, es <strong>soluble o <em>solvable</em></strong>.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(X_{\text{opt}} = \emptyset\)</span> se dice que el valor óptimo no se alcanza. Obsérvese que para problemas no acotados nunca se alcanza el valor óptimo.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(x\)</span> es factible y <span class="math notranslate nohighlight">\(f_o(x) \leq p^* + \epsilon\)</span> con <span class="math notranslate nohighlight">\(\epsilon &gt;0\)</span>, <span class="math notranslate nohighlight">\(x\)</span> se nombra <strong><span class="math notranslate nohighlight">\(\epsilon\)</span>-subóptimo</strong> y el conjunto de puntos <span class="math notranslate nohighlight">\(\epsilon\)</span>-subóptimos se nombra <strong>conjunto <span class="math notranslate nohighlight">\(\epsilon\)</span>-subóptimo</strong>.</p></li>
</ul>
</div>
</div>
<div class="section" id="optimo-local">
<h2>Óptimo local<a class="headerlink" href="#optimo-local" title="Permalink to this headline">¶</a></h2>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se asumen todos los puntos en el dominio del problema de optimización <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</div>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Un punto factible <span class="math notranslate nohighlight">\(x^*\)</span> se nombra <strong>óptimo local</strong> si <span class="math notranslate nohighlight">\(\exists R &gt; 0\)</span> tal que:</p>
<div class="math notranslate nohighlight">
\[f_o(x^*) = \inf \{f_o(z) | f_i(z) \leq 0 \forall i=1,\dots,m, h_i(z) = 0 \forall i=1,\dots, p, ||z-x||_2 \leq R\}.\]</div>
<p>Así, <span class="math notranslate nohighlight">\(x^*\)</span> resuelve:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min f_o(z)\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[f_i(z) \leq 0, \forall i =1,\dots,m\]</div>
<div class="math notranslate nohighlight">
\[h_i(z) =0, \forall i=1,\dots,p\]</div>
<div class="math notranslate nohighlight">
\[||z-x||_2 \leq R\]</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>La palabra <strong>óptimo</strong> se utiliza para <strong>óptimo global</strong>, esto es, no consideramos la última restricción <span class="math notranslate nohighlight">\(||z-x||_2 \leq R\)</span> en el problema de optimización y exploramos en todo el <span class="math notranslate nohighlight">\(\text{dom}f\)</span>.</p>
</div>
<img src="https://dl.dropboxusercontent.com/s/xyprhh7erbb6icb/min-max-points-example.png?dl=0" heigth="700" width="700">
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Es común referirse al conjunto de mínimos y máximos como puntos extremos de una función.</p>
</div>
</div>
<div class="section" id="restricciones-activas-no-activas-y-redundantes">
<h2>Restricciones activas, no activas y redundantes<a class="headerlink" href="#restricciones-activas-no-activas-y-redundantes" title="Permalink to this headline">¶</a></h2>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se asumen todos los puntos en el dominio del problema de optimización <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</div>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Si <span class="math notranslate nohighlight">\(x\)</span> es factible y <span class="math notranslate nohighlight">\(f_i(x)=0\)</span> entonces la restricción de desigualdad <span class="math notranslate nohighlight">\(f_i(x) \leq 0\)</span> se nombra <strong>restricción activa en <span class="math notranslate nohighlight">\(x\)</span></strong>. Se nombra <strong>inactiva en <span class="math notranslate nohighlight">\(x\)</span></strong> si <span class="math notranslate nohighlight">\(f_i(x) &lt;0\)</span> para alguna <span class="math notranslate nohighlight">\(i=1,\dots ,m\)</span>.</p>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Las restricciones de igualdad, <span class="math notranslate nohighlight">\(h_i(x)\)</span>, siempre son activas en el conjunto factible con <span class="math notranslate nohighlight">\(i=1,\dots ,p\)</span>.</p></li>
<li><p>Una restricción se nombra <strong>restricción redundante</strong> si al quitarla el conjunto factible no se modifica.</p></li>
</ul>
</div>
</div>
<div class="section" id="problemas-de-optimizacion-convexa-en-su-forma-estandar-o-canonica">
<h2>Problemas de optimización convexa en su forma estándar o canónica<a class="headerlink" href="#problemas-de-optimizacion-convexa-en-su-forma-estandar-o-canonica" title="Permalink to this headline">¶</a></h2>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se asumen todos los puntos en el dominio del problema de optimización <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recuerda que una función afín es de la forma <span class="math notranslate nohighlight">\(h(x) = Ax+b\)</span> con <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{p \times n}\)</span> y <span class="math notranslate nohighlight">\(b \in \mathbb{R}^p\)</span>. En la definición <span class="math notranslate nohighlight">\(h_i(x) = a_i^Tx-b_i\)</span> con <span class="math notranslate nohighlight">\(a_i \in \mathbb{R}^n\)</span>, <span class="math notranslate nohighlight">\(b_i \in \mathbb{R}\)</span> <span class="math notranslate nohighlight">\(\forall i=1,\dots,p\)</span> y geométricamente <span class="math notranslate nohighlight">\(h_i(x)\)</span> es un <strong>hiperplano</strong> en <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>.</p>
</div>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Se define un problema de optimización convexa en su forma estándar o canónica como:</p>
<div class="math notranslate nohighlight">
\[\displaystyle \min f_o(x)\]</div>
<div class="math notranslate nohighlight">
\[\text{sujeto a:}\]</div>
<div class="math notranslate nohighlight">
\[f_i(x) \leq 0 , i=1,\dots,m\]</div>
<div class="math notranslate nohighlight">
\[h_i(x)=0, i=1,\dots,p\]</div>
<p>donde: <span class="math notranslate nohighlight">\(f_i\)</span> son <strong>convexas</strong> <span class="math notranslate nohighlight">\(\forall i=0,1,\dots,m\)</span> y <span class="math notranslate nohighlight">\(h_i\)</span> <strong>es afín</strong> <span class="math notranslate nohighlight">\(\forall i =1,\dots,p\)</span>.</p>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Un conjunto <span class="math notranslate nohighlight">\(\alpha\)</span>-subnivel es de la forma <span class="math notranslate nohighlight">\(\{x \in \text{dom}f | f(x) \leq \alpha\}\)</span>. Un conjunto subnivel contiene las curvas de nivel de <span class="math notranslate nohighlight">\(f\)</span>, ver <a class="reference external" href="https://en.wikipedia.org/wiki/Level_set">Level set</a>:</p>
<img src="https://dl.dropboxusercontent.com/s/0woqoj8foo5eco9/level_set_of_func.png?dl=0" heigth="300" width="300">
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>El conjunto de factibilidad de un problema de optimización convexa es un conjunto convexo. Esto se sigue pues es una intersección finita de conjuntos convexos: intersección entre las <span class="math notranslate nohighlight">\(x\)</span>’s que satisfacen <span class="math notranslate nohighlight">\(f_i(x) \leq 0\)</span>, <span class="math notranslate nohighlight">\(i=1,\dots ,m\)</span>, que se nombra <strong>conjunto subnivel</strong>, y las <span class="math notranslate nohighlight">\(x\)</span>’s que están en un hiperplano, esto es, que satisfacen <span class="math notranslate nohighlight">\(h_i(x) = 0\)</span>, <span class="math notranslate nohighlight">\(i=1,\dots ,p\)</span>.</p></li>
<li><p>Si en el problema anterior se tiene que <strong>maximizar</strong> una <span class="math notranslate nohighlight">\(f_o\)</span> función objetivo <strong>cóncava</strong> y se tienen misma forma estándar: <span class="math notranslate nohighlight">\(f_i\)</span> convexa, <span class="math notranslate nohighlight">\(h_i\)</span> afín entonces también se nombra al problema como <strong>problema de optimización convexa</strong>. Todos los resultados, conclusiones y algoritmos desarrollados para los problemas de minimización son aplicables para maximización. En este caso se puede resolver un problema de maximización al minimizar la función objetivo  <span class="math notranslate nohighlight">\(-f_o\)</span> que es convexa.</p></li>
</ul>
</div>
</div>
<div class="section" id="funcion-convexa">
<h2>Función convexa<a class="headerlink" href="#funcion-convexa" title="Permalink to this headline">¶</a></h2>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Sea <span class="math notranslate nohighlight">\(f:\mathbb{R}^n \rightarrow \mathbb{R}\)</span> una función con el conjunto <span class="math notranslate nohighlight">\(\text{dom}f\)</span> convexo. <span class="math notranslate nohighlight">\(f\)</span> se nombra convexa  (en su <span class="math notranslate nohighlight">\(\text{dom}f\)</span>) si <span class="math notranslate nohighlight">\(\forall x,y \in \text{dom}f\)</span> y <span class="math notranslate nohighlight">\(\theta \in [0,1]\)</span> se cumple:</p>
<div class="math notranslate nohighlight">
\[f(\theta x + (1-\theta) y) \leq \theta f(x) + (1-\theta)f(y).\]</div>
<p>Si la desigualdad se cumple de forma estricta <span class="math notranslate nohighlight">\(\forall x \neq y\)</span> <span class="math notranslate nohighlight">\(f\)</span> se nombra <strong>estrictamente convexa</strong>.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Observaciones</p>
<ul class="simple">
<li><p>La convexidad de <span class="math notranslate nohighlight">\(f\)</span> se define para <span class="math notranslate nohighlight">\(\text{dom}f\)</span> aunque para casos en particular se detalla el conjunto en el que <span class="math notranslate nohighlight">\(f\)</span> es convexa.</p></li>
<li><p>La desigualdad que define a funciones convexas se nombra <a class="reference external" href="https://en.wikipedia.org/wiki/Jensen%27s_inequality"><strong>desigualdad de Jensen</strong></a>.</p></li>
</ul>
</div>
<div class="section" id="propiedades">
<h3>Propiedades<a class="headerlink" href="#propiedades" title="Permalink to this headline">¶</a></h3>
<p>Entre las propiedades que tiene una función convexa se encuentran las siguientes:</p>
<ul class="simple">
<li><p>Si <span class="math notranslate nohighlight">\(f\)</span> es convexa el conjunto subnivel es un conjunto convexo.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{dom}f\)</span> es convexo <span class="math notranslate nohighlight">\(\therefore\)</span> <span class="math notranslate nohighlight">\(\theta x + (1-\theta)y \in \text{dom}f\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> es <strong>cóncava</strong> si <span class="math notranslate nohighlight">\(-f\)</span> es convexa y <strong>estrictamente cóncava</strong> si <span class="math notranslate nohighlight">\(-f\)</span> es estrictamente convexa. Otra forma de definir concavidad es con una desigualdad del tipo:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[f(\theta x + (1-\theta) y) \geq \theta f(x) + (1-\theta)f(y).\]</div>
<p>y mismas definiciones para <span class="math notranslate nohighlight">\(x,y, \theta\)</span> que en la definición de convexidad.</p>
<ul class="simple">
<li><p>Si <span class="math notranslate nohighlight">\(f\)</span> es convexa, geométricamente el segmento de línea que se forma con los puntos <span class="math notranslate nohighlight">\((x,f(x)), (y,f(y))\)</span> está por encima o es igual a <span class="math notranslate nohighlight">\(f(\theta x + (1-\theta)y) \forall \theta \in [0,1]\)</span> y <span class="math notranslate nohighlight">\(\forall x,y \in \text{dom}f\)</span>:</p></li>
</ul>
<img src="https://dl.dropboxusercontent.com/s/fdcx1k150nfwykv/draw_convexity_for_functions.png?dl=0" heigth="300" width="300">
</div>
</div>
<div class="section" id="conjuntos-convexos">
<h2>Conjuntos convexos<a class="headerlink" href="#conjuntos-convexos" title="Permalink to this headline">¶</a></h2>
<div class="section" id="linea-y-segmentos-de-linea">
<h3>Línea y segmentos de línea<a class="headerlink" href="#linea-y-segmentos-de-linea" title="Permalink to this headline">¶</a></h3>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Sean <span class="math notranslate nohighlight">\(x_1, x_2 \in \mathbb{R}^n\)</span> con <span class="math notranslate nohighlight">\(x_1 \neq x_2\)</span>. Entonces el punto:</p>
<div class="math notranslate nohighlight">
\[y = \theta x_1 + (1-\theta)x_2\]</div>
<p>con <span class="math notranslate nohighlight">\(\theta \in \mathbb{R}\)</span> se encuentra en la línea que pasa por <span class="math notranslate nohighlight">\(x_1\)</span> y <span class="math notranslate nohighlight">\(x_2\)</span>. <span class="math notranslate nohighlight">\(\theta\)</span> se le nombra parámetro y si <span class="math notranslate nohighlight">\(\theta \in [0,1]\)</span> tenemos un segmento de línea:</p>
<img src="https://dl.dropboxusercontent.com/s/dldljf5igy8xt9d/segmento_linea.png?dl=0" heigth="200" width="200">
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y = \theta x_1 + (1-\theta)x_2 = x_2 + \theta(x_1 -x_2)\)</span> y esta última igualdad se interpreta como “<span class="math notranslate nohighlight">\(y\)</span> es la suma del punto base <span class="math notranslate nohighlight">\(x_2\)</span> y la dirección <span class="math notranslate nohighlight">\(x_1-x_2\)</span> escalada por <span class="math notranslate nohighlight">\(\theta\)</span>”.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(\theta=0\)</span> entonces <span class="math notranslate nohighlight">\(y=x_2\)</span>. Si <span class="math notranslate nohighlight">\(\theta \in [0,1]\)</span> entonces <span class="math notranslate nohighlight">\(y\)</span> se “mueve” en la dirección <span class="math notranslate nohighlight">\(x_1-x_2\)</span> hacia <span class="math notranslate nohighlight">\(x_1\)</span> y si <span class="math notranslate nohighlight">\(\theta&gt;1\)</span> entonces <span class="math notranslate nohighlight">\(y\)</span> se encuentra en la línea “más allá” de <span class="math notranslate nohighlight">\(x_1\)</span>:</p></li>
</ul>
<img src="https://dl.dropboxusercontent.com/s/nbahrio7p1mj4hs/segmento_linea_2.png?dl=0" heigth="350" width="350">
<p>El punto entre <span class="math notranslate nohighlight">\(x_1\)</span> y <span class="math notranslate nohighlight">\(x_2\)</span> tiene <span class="math notranslate nohighlight">\(\theta=\frac{1}{2}\)</span>.</p>
</div>
</div>
<div class="section" id="conjunto-convexo">
<h3>Conjunto convexo<a class="headerlink" href="#conjunto-convexo" title="Permalink to this headline">¶</a></h3>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Un conjunto <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> es convexo si el segmento de línea entre cualquier par de puntos de <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> está completamente contenida en <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>. Esto se escribe matemáticamente como:</p>
<div class="math notranslate nohighlight">
\[\theta x_1 + (1-\theta) x_2 \in \mathcal{C} \quad \forall \theta \in [0,1], \forall x_1, x_2 \in \mathcal{C}.\]</div>
</div>
<p>Ejemplos gráficos de conjuntos convexos:</p>
<img src="https://dl.dropboxusercontent.com/s/gj54ism1lqojot6/ej_conj_convexos.png?dl=0" heigth="400" width="400"><p>Ejemplos gráficos de conjuntos no convexos:</p>
<img src="https://dl.dropboxusercontent.com/s/k37zh5v3iq3kx04/ej_conj_no_convexos.png?dl=0" heigth="350" width="350"><div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>El punto <span class="math notranslate nohighlight">\(\displaystyle \sum_{i=1}^k \theta_i x_i\)</span> con <span class="math notranslate nohighlight">\(\displaystyle \sum_{i=1}^k \theta_i=1\)</span>, <span class="math notranslate nohighlight">\(\theta_i \geq 0 \forall i=1,\dots,k\)</span> se nombra <strong>combinación convexa</strong> de los puntos <span class="math notranslate nohighlight">\(x_1, x_2, \dots, x_k\)</span>. Una combinación convexa de los puntos <span class="math notranslate nohighlight">\(x_1, \dots, x_k\)</span> puede pensarse como una mezcla o promedio ponderado de los puntos, con <span class="math notranslate nohighlight">\(\theta_i\)</span> la fracción <span class="math notranslate nohighlight">\(\theta_i\)</span> de <span class="math notranslate nohighlight">\(x_i\)</span> en la mezcla.</p></li>
<li><p>Un conjunto es convexo si y sólo si contiene cualquier combinación convexa de sus puntos.</p></li>
<li><p>El conjunto óptimo y los conjuntos <span class="math notranslate nohighlight">\(\epsilon\)</span>-subóptimos son convexos. Ver definiciones de conjunto óptimo y <span class="math notranslate nohighlight">\(\epsilon\)</span>-subóptimos en <a class="reference internal" href="#poptprobopt"><span class="std std-ref">punto óptimo del problema de optimización</span></a>.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="ejemplos-de-funciones-convexas-y-concavas">
<h2>Ejemplos de funciones convexas y cóncavas<a class="headerlink" href="#ejemplos-de-funciones-convexas-y-concavas" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Una función afín es convexa y cóncava en todo su dominio: <span class="math notranslate nohighlight">\(f(x) = Ax+b\)</span> con <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m \times n}, b \in \mathbb{R}^n\)</span>, <span class="math notranslate nohighlight">\(\text{dom}f = \mathbb{R}^n\)</span>.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>Por tanto las funciones lineales también son convexas y cóncavas.</p>
</div>
<ul class="simple">
<li><p>Funciones cuadráticas: <span class="math notranslate nohighlight">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x) = \frac{1}{2} x^TPx + q^Tx + r\)</span> son convexas en su dominio <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> si <span class="math notranslate nohighlight">\(P \in \mathcal{S}_+^n, q \in \mathbb{R}^n, r \in \mathbb{R}\)</span> con <span class="math notranslate nohighlight">\(\mathbb{S}_+^n\)</span> conjunto de <strong>matrices simétricas positivas semidefinidas</strong>.</p></li>
</ul>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Una matriz <span class="math notranslate nohighlight">\(A\)</span> es positiva semidefinida si <span class="math notranslate nohighlight">\(x^TAx \geq 0\)</span> <span class="math notranslate nohighlight">\(\forall x \in \mathbb{R}^n - \{0\}\)</span>. Si se cumple de forma estricta la desigualdad entonces <span class="math notranslate nohighlight">\(A\)</span> es <strong>positiva definida</strong>. Con los eigenvalores podemos caracterizar a las matrices definidas y semidefinidas positivas: <span class="math notranslate nohighlight">\(A\)</span> es semidefinida positiva si y sólo si los eigenvalores de <span class="math notranslate nohighlight">\(T=\frac{A+A^T}{2}\)</span> son no negativos. Es definida positiva si y sólo si los eigenvalores de <span class="math notranslate nohighlight">\(T\)</span> son positivos. Los conjuntos de matrices que se utilizan para definir a matrices semidefinidas positivas y definidas positivas son <span class="math notranslate nohighlight">\(\mathbb{S}_{+}^n\)</span> y <span class="math notranslate nohighlight">\(\mathbb{S}_{++}^n\)</span> respectivamente (<span class="math notranslate nohighlight">\(\mathbb{S}\)</span> es el conjunto de matrices simétricas).</p>
</div>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p><span class="math notranslate nohighlight">\(f\)</span> es estrictamente convexa si y sólo si <span class="math notranslate nohighlight">\(P \in \mathbb{S}_{++}^n\)</span>. <span class="math notranslate nohighlight">\(f\)</span> es cóncava si y sólo si <span class="math notranslate nohighlight">\(P \in -\mathbb{S}_+^n\)</span>.</p>
</div>
<ul class="simple">
<li><p>Exponenciales: <span class="math notranslate nohighlight">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x) = e^{ax}\)</span> para cualquier <span class="math notranslate nohighlight">\(a \in \mathbb{R}\)</span> es convexa en su dominio <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>.</p></li>
<li><p>Potencias: <span class="math notranslate nohighlight">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x)=x^a\)</span>:</p>
<ul>
<li><p>Si <span class="math notranslate nohighlight">\(a \geq 1\)</span> o <span class="math notranslate nohighlight">\(a \leq 0\)</span> entonces <span class="math notranslate nohighlight">\(f\)</span> es convexa en <span class="math notranslate nohighlight">\(\mathbb{R}_{++}\)</span> (números reales positivos).</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(0 \leq a \leq 1\)</span> entonces <span class="math notranslate nohighlight">\(f\)</span> es cóncava en <span class="math notranslate nohighlight">\(\mathbb{R}_{++}\)</span>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Potencias del valor absoluto: <span class="math notranslate nohighlight">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x)=|x|^p\)</span> con <span class="math notranslate nohighlight">\(p \geq 1\)</span> es convexa en <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>.</p></li>
<li><p>Logaritmo: <span class="math notranslate nohighlight">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x) = \log(x)\)</span> es cóncava en su dominio: <span class="math notranslate nohighlight">\(\mathbb{R}_{++}\)</span>.</p></li>
<li><p>Entropía negativa: <span class="math notranslate nohighlight">\(f(x) = \begin{cases}
x\log(x) &amp;\text{ si } x &gt; 0 ,\\
0 &amp;\text{ si } x = 0
\end{cases}\)</span> es estrictamente convexa en su dominio <span class="math notranslate nohighlight">\(\mathbb{R}_+\)</span>.</p></li>
<li><p>Normas: cualquier norma es convexa en su dominio.</p></li>
<li><p>Función máximo: <span class="math notranslate nohighlight">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x) = \max\{x_1,\dots,x_n\}\)</span> es convexa.</p></li>
<li><p>Función log-sum-exp: <span class="math notranslate nohighlight">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x)=\log\left(\displaystyle \sum_{i=1}^ne^{x_i}\right)\)</span> es convexa en su dominio <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>.</p></li>
<li><p>La media geométrica: <span class="math notranslate nohighlight">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(f(x) = \left(\displaystyle \prod_{i=1}^n x_i \right)^\frac{1}{n}\)</span> es cóncava en su dominio <span class="math notranslate nohighlight">\(\mathbb{R}_{++}^n\)</span>.</p></li>
<li><p>Función log-determinante: <span class="math notranslate nohighlight">\(f: \mathbb{S}^{n} \rightarrow \mathbb{R}^n\)</span>, <span class="math notranslate nohighlight">\(f(x) = \log(\det(X))\)</span> es cóncava en su dominio <span class="math notranslate nohighlight">\(\mathbb{S}_{++}^n\)</span>.</p></li>
</ul>
</div>
<div class="section" id="resultados-utiles-de-teoria-de-convexidad">
<span id="resutteoconv"></span><h2>Resultados útiles de teoría de convexidad<a class="headerlink" href="#resultados-utiles-de-teoria-de-convexidad" title="Permalink to this headline">¶</a></h2>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Se sugiere revisar <a class="reference internal" href="../../I.computo_cientifico/1.5/Definicion_de_funcion_continuidad_derivada.html#fcd"><span class="std std-ref">definición de función, continuidad y derivada</span></a> y <a class="reference internal" href="../../I.computo_cientifico/1.4/Condicion_de_un_problema_y_estabilidad_de_un_algoritmo.html#cpea"><span class="std std-ref">condición de un problema y estabilidad de un algoritmo</span></a> como recordatorio de definiciones. En particular las <strong>definiciones de primera y segunda derivada, gradiente y Hessiana</strong> para la primer nota y la <strong>definición de número de condición de una matriz</strong> para la segunda.</p>
</div>
<div class="section" id="sobre-funciones-convexas-concavas">
<h3>Sobre funciones convexas/cóncavas<a class="headerlink" href="#sobre-funciones-convexas-concavas" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Sea <span class="math notranslate nohighlight">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> diferenciable entonces <span class="math notranslate nohighlight">\(f\)</span> es convexa si y sólo si <span class="math notranslate nohighlight">\(\text{dom}f\)</span> es un conjunto convexo y se cumple:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[f(y) \geq f(x) + \nabla f(x)^T(y-x) \forall x,y \in \text{dom}f.\]</div>
<p>Si se cumple de forma estricta la desigualdad <span class="math notranslate nohighlight">\(f\)</span> se nombra estrictamente convexa. También si su <span class="math notranslate nohighlight">\(\text{dom}f\)</span> es convexo y se tiene la desigualdad en la otra dirección “<span class="math notranslate nohighlight">\(\leq\)</span>” entonces <span class="math notranslate nohighlight">\(f\)</span> es cóncava.</p>
<p>Geométricamente este resultado se ve como sigue para <span class="math notranslate nohighlight">\(\nabla f(x) \neq 0\)</span>:</p>
<img src="https://dl.dropboxusercontent.com/s/e581e22xeejdwu0/convexidad_con_hiperplano_de_soporte.png?dl=0" heigth="350" width="350">
<p>y el hiperplano <span class="math notranslate nohighlight">\(f(x) + \nabla f(x)^T(y-x)\)</span> se nombra <strong>hiperplano de soporte para la función <span class="math notranslate nohighlight">\(f\)</span> en el punto <span class="math notranslate nohighlight">\((x,f(x))\)</span></strong>. Obsérvese que si <span class="math notranslate nohighlight">\(\nabla f(x)=0\)</span> se tiene <span class="math notranslate nohighlight">\(f(y) \geq f(x) \forall y \in \text{dom}f\)</span> y por lo tanto <span class="math notranslate nohighlight">\(x\)</span> es un mínimo global de <span class="math notranslate nohighlight">\(f\)</span>.</p>
<ul class="simple">
<li><p>Una función es convexa si y sólo si es convexa al restringirla a cualquier línea que intersecte su dominio, esto es, si <span class="math notranslate nohighlight">\(g(t) = f(x + tv)\)</span> es convexa <span class="math notranslate nohighlight">\(\forall x,v \in \mathbb{R}^n\)</span>, <span class="math notranslate nohighlight">\(\forall t \in \mathbb{R}\)</span> talque <span class="math notranslate nohighlight">\(x + tv \in \text{dom}f\)</span></p></li>
</ul>
<ul class="simple">
<li><p>Sea <span class="math notranslate nohighlight">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> tal que <span class="math notranslate nohighlight">\(f \in \mathcal{C}^2(\text{dom}f)\)</span>. Entonces <span class="math notranslate nohighlight">\(f\)</span> es convexa en <span class="math notranslate nohighlight">\(\text{dom}f\)</span> si y sólo si <span class="math notranslate nohighlight">\(\text{dom}f\)</span> es convexo y <span class="math notranslate nohighlight">\(\nabla^2f(x) \in \mathbb{S}^n_+\)</span> en <span class="math notranslate nohighlight">\(\text{dom}f\)</span>. Si <span class="math notranslate nohighlight">\(\nabla^2f(x) \in \mathbb{S}^n_{++}\)</span> en <span class="math notranslate nohighlight">\(\text{dom}f\)</span> y <span class="math notranslate nohighlight">\(\text{dom}f\)</span> es convexo entonces <span class="math notranslate nohighlight">\(f\)</span> es estrictamente convexa en <span class="math notranslate nohighlight">\(\text{dom}f\)</span>.</p></li>
</ul>
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Para una función: <span class="math notranslate nohighlight">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>, la hipótesis del enunciado anterior (<span class="math notranslate nohighlight">\(\nabla^2 f(x) \in \mathbb{S}^n_{++}\)</span> en <span class="math notranslate nohighlight">\(\text{dom}f\)</span>) es que la segunda derivada sea positiva. El recíproco no es verdadero, para ver esto considérese <span class="math notranslate nohighlight">\(f(x)=x^4\)</span> la cual es estrictamente convexa en <span class="math notranslate nohighlight">\(\text{dom}f\)</span> pero su segunda derivada en <span class="math notranslate nohighlight">\(0\)</span> no es positiva.</p>
</div>
</div>
<div class="section" id="sobre-problemas-de-optimizacion">
<h3>Sobre problemas de optimización<a class="headerlink" href="#sobre-problemas-de-optimizacion" title="Permalink to this headline">¶</a></h3>
<p>Para problemas de optimización sin restricciones:</p>
<ul class="simple">
<li><p>Si <span class="math notranslate nohighlight">\(f\)</span> es diferenciable y <span class="math notranslate nohighlight">\(x^*\)</span> es óptimo entonces <span class="math notranslate nohighlight">\(\nabla f(x^*) = 0\)</span>.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(f \in \mathcal{C}^2(\text{domf})\)</span> y <span class="math notranslate nohighlight">\(x^*\)</span> es mínimo local entonces <span class="math notranslate nohighlight">\(\nabla^2 f(x^*)\)</span> es una matriz simétrica semidefinida positiva.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(f \in \mathcal{C}^2(\text{domf})\)</span>, <span class="math notranslate nohighlight">\(\nabla f(x^*)=0\)</span> y <span class="math notranslate nohighlight">\(\nabla^2f(x^*)\)</span> es una matriz simétrica definida positiva entonces <span class="math notranslate nohighlight">\(x^*\)</span> es mínimo local estricto.</p></li>
</ul>
<p>Para problemas de optimización convexa:</p>
<ul class="simple">
<li><p>Una propiedad fundamental de un óptimo local en un problema de optimización convexa es que también es un óptimo global. Si la función es estrictamente convexa entonces el conjunto óptimo contiene a lo más un punto.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(f_o\)</span> es diferenciable y <span class="math notranslate nohighlight">\(X\)</span> es el conjunto de factibilidad entonces <span class="math notranslate nohighlight">\(x\)</span> es óptimo si y sólo si <span class="math notranslate nohighlight">\(x \in X\)</span> y <span class="math notranslate nohighlight">\(\nabla f_o(x)^T(y-x) \geq 0\)</span> <span class="math notranslate nohighlight">\(\forall y \in X\)</span>. Si se considera como conjunto de factibilidad <span class="math notranslate nohighlight">\(X = \text{dom}f_o\)</span> (que es un problema sin restricciones) la propiedad se reduce a la condición: <span class="math notranslate nohighlight">\(x\)</span> es óptimo si y sólo si <span class="math notranslate nohighlight">\(\nabla f_o(x) = 0\)</span>.</p></li>
</ul>
<p>Geométricamente el resultado anterior se visualiza para <span class="math notranslate nohighlight">\(\nabla f(x) \neq 0\)</span> y <span class="math notranslate nohighlight">\(-\nabla f(x)\)</span> apuntando hacia la dirección dibujada:</p>
<img src="https://dl.dropboxusercontent.com/s/0tmpivvo5ob4oox/optimo_convexidad_con_hiperplano_de_soporte.png?dl=0" heigth="550" width="550">
<div class="admonition-comentario admonition">
<p class="admonition-title">Comentario</p>
<p>Por los resultados anteriores los métodos de optimización buscan resolver la <strong>ecuación no lineal</strong> <span class="math notranslate nohighlight">\(\nabla f_o(x)=0\)</span> para aproximar en general mínimos locales. Dependiendo del número de soluciones de la ecuación <span class="math notranslate nohighlight">\(\nabla f_o(x)=0\)</span> se tienen situaciones distintas. Por ejemplo, si no tiene solución entonces el/los óptimos no se alcanza(n) pues el problema puede no ser acotado por debajo o si existe el óptimo éste puede no alcanzarse. Por otro lado, si la ecuación tiene múltiples soluciones entonces cada solución es un mínimo de <span class="math notranslate nohighlight">\(f_o\)</span>.</p>
</div>
</div>
<div class="section" id="sobre-puntos-criticos">
<span id="spcriticos"></span><h3>Sobre puntos críticos<a class="headerlink" href="#sobre-puntos-criticos" title="Permalink to this headline">¶</a></h3>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Puntos <span class="math notranslate nohighlight">\(x \in \text{intdom}f\)</span> en los que <span class="math notranslate nohighlight">\(\nabla f(x) = 0\)</span>  o en los que <span class="math notranslate nohighlight">\(\nabla f\)</span> no existe, se les nombra <strong>puntos críticos o estacionarios</strong> de <span class="math notranslate nohighlight">\(f\)</span>.</p>
</div>
<ul class="simple">
<li><p>No todo punto crítico es un extremo de <span class="math notranslate nohighlight">\(f\)</span>.</p></li>
<li><p>La Hessiana de <span class="math notranslate nohighlight">\(f\)</span> nos ayuda a caracterizar los puntos críticos en mínimos o máximos locales. Si <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> es punto crítico:</p>
<ul>
<li><p>Y además <span class="math notranslate nohighlight">\(\nabla^2f(x) \in \mathbb{S}_{++}\)</span> entonces <span class="math notranslate nohighlight">\(x\)</span> es mínimo local.</p></li>
<li><p>Y además <span class="math notranslate nohighlight">\(\nabla^2f(x) \in -\mathbb{S}_{++}\)</span> entonces <span class="math notranslate nohighlight">\(x\)</span> es máximo local.</p></li>
<li><p>Y además <span class="math notranslate nohighlight">\(\nabla^2f(x)\)</span> es indefinida entonces <span class="math notranslate nohighlight">\(x\)</span> se nombra punto silla o <a class="reference external" href="https://en.wikipedia.org/wiki/Saddle_point"><em>saddle point</em></a>.</p></li>
</ul>
</li>
<li><p>Si <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> es punto crítico y <span class="math notranslate nohighlight">\(\nabla^2f(x) \in \mathbb{S}_{+}\)</span> no podemos concluir si es máximo o mínimo local (análogo si <span class="math notranslate nohighlight">\(\nabla^2f(x) \in -\mathbb{S}_{+}\)</span>).</p></li>
</ul>
</div>
</div>
<div class="section" id="funcion-fuertemente-convexa">
<h2>Función fuertemente convexa<a class="headerlink" href="#funcion-fuertemente-convexa" title="Permalink to this headline">¶</a></h2>
<div class="admonition-definicion admonition">
<p class="admonition-title">Definición</p>
<p>Una función <span class="math notranslate nohighlight">\(f:\mathbb{R}^n \rightarrow \mathbb{R}\)</span> tal que <span class="math notranslate nohighlight">\(f \in \mathcal{C}^2(\text{dom}f)\)</span> se nombra <strong>fuertemente convexa</strong> en el conjunto convexo <span class="math notranslate nohighlight">\(\mathcal{S} \neq \emptyset\)</span> si existe <span class="math notranslate nohighlight">\(m&gt;0\)</span> tal que <span class="math notranslate nohighlight">\(\nabla^2 f(x) - mI\)</span> es simétrica semidefinida positiva <span class="math notranslate nohighlight">\(\forall x \in \mathcal{S}\)</span>.</p>
</div>
<div class="admonition-comentarios admonition">
<p class="admonition-title">Comentarios</p>
<ul class="simple">
<li><p>Es equivalente escribir que una función <span class="math notranslate nohighlight">\(f\)</span> es fuertemente convexa en un conjunto <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> que escribir <span class="math notranslate nohighlight">\(\lambda_{\text{min}} (\nabla^2 f(x))\)</span> es positivo para toda <span class="math notranslate nohighlight">\(x \in \mathcal{S}\)</span>.</p></li>
<li><p>Si una función es fuertemente convexa se puede probar que:</p>
<ul>
<li><p>El conjunto óptimo contiene a lo más un punto.</p></li>
<li><p><span class="math notranslate nohighlight">\(f(y) \geq f(x) + \nabla f(x)^T(y-x) + \frac{m}{2}||y-x||_2^2 \forall x,y \in \mathcal{S}\)</span>. Por esto si <span class="math notranslate nohighlight">\(f\)</span> es fuertemente convexa en <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> entonces es estrictamente convexa en <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. También esta desigualdad indica que la diferencia entre la función de <span class="math notranslate nohighlight">\(y\)</span>, <span class="math notranslate nohighlight">\(f(y)\)</span>, y la función lineal en <span class="math notranslate nohighlight">\(y\)</span> <span class="math notranslate nohighlight">\(f(x) + \nabla f(x)^T(y-x)\)</span> (Taylor a primer orden) está acotada por debajo por una cantidad cuadrática.</p></li>
<li><p>Existe una cota superior para el <strong>número de condición</strong> bajo la norma 2 de la Hessiana de <span class="math notranslate nohighlight">\(f\)</span>, esto es: <span class="math notranslate nohighlight">\(\nabla ^2 f(x)\)</span>= <span class="math notranslate nohighlight">\(\frac{\lambda_\text{max}(\nabla^2 f(x))}{\lambda_\text{min}(\nabla^2 f(x))} \leq K\)</span> con <span class="math notranslate nohighlight">\(K&gt;0\)</span>, <span class="math notranslate nohighlight">\(\forall x \in \mathcal{S}\)</span>.</p></li>
</ul>
</li>
</ul>
</div>
<div class="tip admonition">
<p class="admonition-title">Observaciones</p>
<ul class="simple">
<li><p>La condición que una función sea fuertemente convexa garantiza que el número de condición de la Hessiana de <span class="math notranslate nohighlight">\(f\)</span> es una buena medida del desempeño de los algoritmos de optimización convexa sin restricciones (se revisará más adelante).</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> es fuertemente convexa en <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> entonces es estrictamente convexa en <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> pero no viceversa, considérese por ejemplo <span class="math notranslate nohighlight">\(f=x^4\)</span> la cual es estrictamente convexa en todo su dominio pero no es fuertemente convexa en todo su dominio pues su segunda derivada se anula en <span class="math notranslate nohighlight">\(x=0\)</span>.</p></li>
</ul>
</div>
<p><strong>Preguntas de comprehensión.</strong></p>
<ol class="simple">
<li></li>
</ol>
<p><strong>Referencias:</strong></p>
<ol class="simple">
<li><p>S. P. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, 2009.</p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "palmoreck/dockerfiles-for-binder",
            ref: "jupyterlab_optimizacion",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./III.optimizacion_convexa/3.1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../../II.computo_matricial/2.4/Valores_vectores_singulares_y_algoritmos_para_calcular_la_SVD.html" title="previous page">2.4 Valores, vectores singulares y algoritmos para calcular la SVD</a>
    <a class='right-next' id="next-link" href="../3.2/Algoritmos_de_descenso_y_busqueda_de_linea_funciones_convexas.html" title="next page">3.2 Algoritmos de descenso y búsqueda de línea para funciones convexas</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Erick Palacios Moreno<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
  </body>
</html>